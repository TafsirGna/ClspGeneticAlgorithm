package main;

import java.util.AbstractMap;
import java.util.ArrayList;
import java.util.Collections;
import java.util.LinkedList;
import java.util.Map;
import java.util.Random;

public class MCTS {

    private Random random;
    private Node rootNode;
    private double explorationConstant = Math.sqrt(2.0);
    private double pessimisticBias;
    private double optimisticBias;

    private boolean scoreBounds;
    private boolean trackTime; // display thinking time used
    private FinalSelectionPolicy finalSelectionPolicy;

    private HeuristicFunction heuristic;

    public MCTS() {
        random = new Random();
    }

    /**
     * Run a UCT-MCTS simulation for a number of iterations.
     *
     * @param startingBoard starting board
     * @param runs how many iterations to think
     * @param bounds enable or disable score bounds.
     * @return
     */
    public Move runMCTS(Board startingBoard, int runs, boolean bounds, boolean ucbStandard) {
//            if(startingBoard == null)
//                            System.out.println("starting board is null");
//                        else
//                            System.out.println("starting board is not null");
        scoreBounds = bounds;
        rootNode = new Node(startingBoard);

        long startTime = System.nanoTime();

        for (int i = 0; i < runs; i++) {
            select(startingBoard.duplicate(), rootNode, ucbStandard);
        }

        long endTime = System.nanoTime();

        if (this.trackTime) {
            System.out.println("Making choice for player: " + rootNode.player + " using standard UCB formula :" + ucbStandard);
            System.out.println("Thinking time per move in milliseconds: " + (endTime - startTime) / 1000000);
        }

        return finalMoveSelection(startingBoard, rootNode);
    }

    /**
     * This represents the select stage, or default policy, of the algorithm.
     * Traverse down to the bottom of the tree using the selection strategy
     * until you find an unexpanded child node. Expand it. Run a random playout.
     * Backpropagate results of the playout.
     *
     * @param node Node from which to start selection
     * @param brd Board state to work from.
     */
    private void select(Board currentBoard, Node currentNode, boolean ucbStandard) {
//            if(currentBoard == null)
//                            System.out.println("current board is null");
//                        else
//                            System.out.println("current board is not null");
        // Begin tree policy. Traverse down the tree and expand. Return
        // the new node or the deepest node it could reach. Return too
        // a board matching the returned node.
        Map.Entry<Board, Node> boardNodePair = treePolicy(currentBoard, currentNode);

        // Run a random playout until the end of the game.
        double[] score = playout(boardNodePair.getValue(), boardNodePair.getKey(), ucbStandard);

        // Backpropagate results of playout.
        Node n = boardNodePair.getValue();
        n.backPropagateScore(score);
        if (scoreBounds) {
            n.backPropagateBounds(score);
        }
    }

    private Map.Entry<Board, Node> treePolicy(Board b, Node node) {
//            if(b == null)
//                            System.out.println("b is null");
//                        else
//                            System.out.println("b is not null");
        while (!b.gameOver()) {
            if (node.unvisitedChildren == null) {
                node.expandNode(b);
            }

            if (!node.unvisitedChildren.isEmpty()) {
                Node temp = node.unvisitedChildren.remove(random.nextInt(node.unvisitedChildren.size()));
                node.children.add(temp);
                b.makeMove(temp.move);
                return new AbstractMap.SimpleEntry<>(b, temp);
            } else {
                ArrayList<Node> bestNodes = findChildren(node, b, optimisticBias, pessimisticBias, explorationConstant);

                if (bestNodes.isEmpty()) {
                    // We have failed to find a single child to visit
                    // from a non-terminal node, so we conclude that
                    // all children must have been PRUNED, and that 
                    // therefore there is no reason to continue.
                    return new AbstractMap.SimpleEntry<>(b, node);
                }

                Node finalNode = bestNodes.get(random.nextInt(bestNodes.size()));
                node = finalNode;
                b.makeMove(finalNode.move);
            }
        }

        return new AbstractMap.SimpleEntry<>(b, node);
    }

    /**
     * This is the final step of the algorithm, to pick the best move to
     * actually make.
     *
     * @param n this is the node whose children are considered
     * @return the best Move the algorithm can find
     */
    private Move finalMoveSelection(Board b, Node n) {
        Node r = null;

        switch (finalSelectionPolicy) {
            case maxChild:
                r = maxChild(n);
                break;
            case robustChild:
                r = robustChild(b, n);
                break;
            default:
                r = robustChild(b, n);
                break;
        }

        return r.move;
    }

//    public void printNodes(Board b, Node node) {
//        DefaultMutableTreeNode racine = new DefaultMutableTreeNode(node.score[0] + "/" + node.score[1] + "/" + node.games);
//        //while(!node.getChilds().isEmpty()){            
//        ArrayList<Node> childs = node.children;
////        System.out.println("Tous les enfants");
//        for (Node child : childs) {
//            Board bmp = b.duplicate();
//            bmp.makeMove(child.move);
////            bmp.bPrint();
////                        child.printinfo();
////                        System.out.println("sa valeur est "+new Node(bmp).myupperConfidenceBound(Math.sqrt(2.0))+"\n\n\n");
////                DefaultMutableTreeNode rac = new DefaultMutableTreeNode(child.score[0]+"/"+child.score[1]+"/"+child.games+"/"+child.myupperConfidenceBound(Math.sqrt(2.0)));
//            DefaultMutableTreeNode rac = new DefaultMutableTreeNode(new Node(bmp).myupperConfidenceBound());
//            racine.add(rac);
//            //printNodes(node);
//        }
////        System.out.println("Fin de tous les enfants");
//        //}
//        //JTree jt = new JTree(racine);
//        TreeModel tm = new DefaultTreeModel(racine);
//        Arbre arbre = new Arbre();
//        //arbre.setjTree1(jt);
//        arbre.getTree().setModel(tm);
//        arbre.setVisible(true);
//    }
    /**
     * Select the most visited child node
     *
     * @param n
     * @return
     */
    private Node robustChild(Board b, Node n) {
//        if (!ucbStandard) {
//            printNodes(b, n);
//        }
        double bestValue = Double.NEGATIVE_INFINITY;
        double tempBest;
        ArrayList<Node> bestNodes = new ArrayList<Node>();

//        if (ucbStandard) {
        for (Node s : n.children) {
            tempBest = s.games;
            //tempBest += s.opti[n.player] * optimisticBias;
            //tempBest += s.pess[n.player] * pessimisticBias;
            if (tempBest > bestValue) {
                bestNodes.clear();
                bestNodes.add(s);
                bestValue = tempBest;
            } else if (tempBest == bestValue) {
                bestNodes.add(s);
            }
        }
//        } else {
//            for (Node s : n.children) {
//                Board bmp = b.duplicate();
//                bmp.makeMove(s.move);
//                tempBest = new Node(bmp).myupperConfidenceBound();
////                System.out.println("tempBest = "+tempBest);
//                if (tempBest > bestValue) {
//                    bestNodes.clear();
//                    bestNodes.add(s);
//                    bestValue = tempBest;
//                } else if (tempBest == bestValue) {
//                    bestNodes.add(s);
//                }
//                //System.out.println("tempBest = "+tempBest);
//            }
//        }

        Node finalNode = bestNodes.get(random.nextInt(bestNodes.size()));
//                finalNode.printinfo();
        return finalNode;
    }

    /**
     * Select the child node with the highest score
     *
     * @param n
     * @return
     */
    private Node maxChild(Node n) {
        double bestValue = Double.NEGATIVE_INFINITY;
        double tempBest;
        ArrayList<Node> bestNodes = new ArrayList<Node>();

        for (Node s : n.children) {
            tempBest = s.score[n.player];
            if (tempBest > bestValue) {
                bestNodes.clear();
                bestNodes.add(s);
                bestValue = tempBest;
            } else if (tempBest == bestValue) {
                bestNodes.add(s);
            }
        }

        Node finalNode = bestNodes.get(random.nextInt(bestNodes.size()));

        return finalNode;
    }

    /**
     * Playout function for MCTS
     *
     * @param state
     * @return
     */
    private double[] playout(Node state, Board board, boolean ucbStandard) {
        ArrayList<Move> moves;
        Move mv;
        Board brd = board.duplicate();

        if (ucbStandard) {
            // Start playing random moves until the game is over
            while (!brd.gameOver()) {
                moves = brd.getMoves(CallLocation.treePolicy);
                mv = moves.get(random.nextInt(moves.size()));

                brd.makeMove(mv);
            }
        } else {
            while (!brd.gameOver()) {
                if (state.unvisitedChildren == null) {
                    state.expandNode(brd);
                    for (int i = state.unvisitedChildren.size() - 1; i >= 0; i--) {
                        Node tmp = state.unvisitedChildren.remove(i);
                        state.children.add(tmp);
                    }
                }

                ArrayList<Node> bestNodes = findChildren(state, board);

                Node finalNode = bestNodes.get(random.nextInt(bestNodes.size()));
                brd.makeMove(finalNode.move);
            }
//            System.out.println("fin");
        }
        return brd.getScore();
    }

//	private Move getRandomMove(Board board, ArrayList<Move> moves) {
//		double []weights = board.getMoveWeights();
//		
//		double totalWeight = 0.0d;
//		for (int i = 0; i < weights.length; i++)
//		{
//		    totalWeight += weights[i];
//		}
//		
//		int randomIndex = -1;
//		double random = Math.random() * totalWeight;
//		for (int i = 0; i < weights.length; ++i)
//		{
//		    random -= weights[i];
//		    if (random <= 0.0d)
//		    {
//		        randomIndex = i;
//		        break;
//		    }
//		}
//		
//		return moves.get(randomIndex);
//	}
    private ArrayList<Node> findChildren(Node n, Board board) {
        double bestValue = Double.NEGATIVE_INFINITY;
        ArrayList<Node> bestNodes = new ArrayList<Node>();
        LinkedList<Integer> lklst = new LinkedList<>();
        LinkedList<Node> lklst1 = new LinkedList<>();

        for (Node s : n.children) {
			// Pruned is only ever true if a branch has been pruned 
            // from the tree and that can only happen if bounds 
            // propagation mode is enabled.
//            if (s.pruned == false) {

            double tempBest;
            Move m = s.move;
            Board bmp = board.duplicate();
            bmp.makeMove(m);
            Node no = new Node(bmp);
            tempBest = no.stateEvaluation();
//                if(tempBest > 0.0)
//                    System.out.println("eval "+tempBest);
            lklst.add((int) tempBest);
            lklst1.add(s);
//                System.out.println("tmp "+tempBest);
//                tre.put((int)tempBest, s);

//                if (tempBest > bestValue) {
//                    // If we found a better node
//                    bestNodes.clear();
//                    bestNodes.add(s);
//                    bestValue = tempBest;
//                } else if (tempBest == bestValue) {
//                    // If we found an equal node
//                    bestNodes.add(s);
//                }                                
//            }
        }
//        System.out.println("tr "+tre.size());

        for (int v = 0; v < lklst.size() / 4 + 1; v++) {
            int ind = lklst.indexOf(Collections.max(lklst));
            bestNodes.add(lklst1.get(ind));
            lklst.set(ind, Integer.MIN_VALUE);
        }

        //children.add(bestNodes);
        //children.add(mybestNodes);
        return bestNodes;
    }

    /**
     * Produce a list of viable nodes to visit. The actual selection is done in
     * runMCTS
     *
     * @param optimisticBias
     * @param pessimisticBias
     * @param explorationConstant
     * @return
     */
    public ArrayList<Node> findChildren(Node n, Board b, double optimisticBias, double pessimisticBias, double explorationConstan) {
        //ArrayList<ArrayList<Node>> children = new ArrayList<>();
        double bestValue = Double.NEGATIVE_INFINITY;
        //double mybestValue = Double.NEGATIVE_INFINITY;
        ArrayList<Node> bestNodes = new ArrayList<Node>();
        //ArrayList<Node> mybestNodes = new ArrayList<Node>();
        for (Node s : n.children) {
            // Pruned is only ever true if a branch has been pruned 
            // from the tree and that can only happen if bounds 
            // propagation mode is enabled.
            if (s.pruned == false) {
                double tempBest;
//                            if(ucbStandard){
                tempBest = s.upperConfidenceBound(explorationConstant)
                        + optimisticBias * s.opti[n.player - 1]
                        + pessimisticBias * s.pess[n.player - 1];
//                            }else{
//                                tempBest = s.myupperConfidenceBound()
//						+optimisticBias * s.opti[n.player-1]
//						+pessimisticBias * s.pess[n.player-1];
//                            }

//                                double mytempBest = s.myupperConfidenceBound(explorationConstant)
//						+optimisticBias * s.opti[n.player-1]
//						+pessimisticBias * s.pess[n.player-1];
                if (heuristic != null) {
                    tempBest += heuristic.h(b);
                    //mytempBest += heuristic.h(b);
                }

                if (tempBest > bestValue) {
                    // If we found a better node
                    bestNodes.clear();
                    bestNodes.add(s);
                    bestValue = tempBest;
                } else if (tempBest == bestValue) {
                    // If we found an equal node
                    bestNodes.add(s);
                }

//                                
            }
        }
        //children.add(bestNodes);
        //children.add(mybestNodes);
        return bestNodes;
    }

    /**
     * Sets the exploration constant for the algorithm. You will need to find
     * the optimal value through testing. This can have a big impact on
     * performance. Default value is sqrt(2)
     *
     * @param exp
     */
    public void setExplorationConstant(double exp) {
        explorationConstant = exp;
    }

    public void setMoveSelectionPolicy(FinalSelectionPolicy policy) {
        finalSelectionPolicy = policy;
    }

    public void setHeuristicFunction(HeuristicFunction h) {
        heuristic = h;
    }

    /**
     * This is multiplied by the pessimistic bounds of any considered move
     * during selection.
     *
     * @param b
     */
    public void setPessimisticBias(double b) {
        pessimisticBias = b;
    }

    /**
     * This is multiplied by the optimistic bounds of any considered move during
     * selection.
     *
     * @param b
     */
    public void setOptimisticBias(double b) {
        optimisticBias = b;
    }

    public void setTimeDisplay(boolean displayTime) {
        this.trackTime = displayTime;
    }

}
